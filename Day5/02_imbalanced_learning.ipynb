{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with imbalanded classification data\n",
    "\n",
    "Author: [Thomas Moreau](https://tommoral.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will need the imabalanced learn package (doc available here: https://imbalanced-learn.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in /home/tom/.local/miniconda/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /home/tom/.local/miniconda/lib/python3.7/site-packages (from imbalanced-learn) (1.17.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/tom/.local/miniconda/lib/python3.7/site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21 in /home/tom/.local/miniconda/lib/python3.7/site-packages (from imbalanced-learn) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /home/tom/.local/miniconda/lib/python3.7/site-packages (from imbalanced-learn) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem of class imbalanced in supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight the issue of working with imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the issue of imbalance learn, we will use the `adult_census` dataset.  \n",
    "A complete description of the data can be found [here](https://www.openml.org/d/1590). Basically, the task is to predict whether an individual will have an annual income of more than 50K dollars based on his personal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://www.openml.org/data/get_csv/1595261/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
       "0   25     Private  226802           11th              7        Never-married   \n",
       "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?  103497   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   class  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              50   United-States   <=50K  \n",
       "2             0              40   United-States    >50K  \n",
       "3             0              40   United-States    >50K  \n",
       "4             0              30   United-States   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Categorial variable</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>33906</td>\n",
       "      <td>15784</td>\n",
       "      <td>22379</td>\n",
       "      <td>6172</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>43832</td>\n",
       "      <td>37155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass education       marital-status       occupation relationship  \\\n",
       "count      48842     48842                48842            48842        48842   \n",
       "unique         9        16                    7               15            6   \n",
       "top      Private   HS-grad   Married-civ-spouse   Prof-specialty      Husband   \n",
       "freq       33906     15784                22379             6172        19716   \n",
       "\n",
       "          race    sex  native-country   class  \n",
       "count    48842  48842           48842   48842  \n",
       "unique       5      2              42       2  \n",
       "top      White   Male   United-States   <=50K  \n",
       "freq     41762  32650           43832   37155  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Numerical variable</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
       "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    48842.000000  \n",
       "mean        40.422382  \n",
       "std         12.391444  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<h3>Categorial variable</h3>\"))\n",
    "display(df.describe(exclude=np.number))\n",
    "display(HTML(\"<h3>Numerical variable</h3>\"))\n",
    "display(df.describe(exclude=np.object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the target column, here called `class` which we will be using to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' <=50K': 37155, ' >50K': 11687})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(df['class'])\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the classes, we can observe that there is 2 classes: `' >50K'` and `' <=50K'`.\n",
    "In addition, we can see that there is a difference regarding the classes frequencies. We can compute the balancing ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.179173440574998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[' <=50K'] / counter[' >50K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check what it would imply if we are not careful when evaluating our model. We will train a `DummyClassifier` which will not predict by learning anything from the data but rather predict the most frequent class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data. We extract the labels\n",
    "# We drop the fnlwgt feature which is not informative in\n",
    "# this context (see data description for more info).\n",
    "target_name = \"class\"\n",
    "target = df[target_name].to_numpy()\n",
    "data = df.drop(columns=[target_name, \"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the classifier always outputs the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K'], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.predict([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dummy_clf.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what it implies regarding the default metric with scikit-learn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the most-frequent model is 0.761\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of the most-frequent model is \"\n",
    "      f\"{dummy_clf.score(data, target):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the default model is 0.761\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy of the default model is \"\n",
    "      f\"{accuracy_score(target, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can here see the main issue: **Unlike with balanced learning, the naive classification level is not `0.5`**.  \n",
    "It is necessary to take into account the class unbalance to help the model learn something meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Use one or several informative metrics to detect the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the `accuracy_score`, one could use the `balanced_accuracy_score`.\n",
    "*Slight issue:* not everyone agrees on the definition of the metric.\n",
    "\n",
    "The `balanced_accuracy` avoids inflated performance estimates on imbalanced datasets:\n",
    "* If the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to $\\frac{1}{n_{classes}}$.\n",
    "* If the classifier performs equally well on either class, this term reduces to the conventional accuracy (*i.e.*, the number of correct predictions divided by the total number of predictions).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Details:* It is the raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Given predicted $\\widehat y_i$ for sample $i$, balanced accuracy is defined as:\n",
    "$$\n",
    "    \\texttt{balanced-accuracy}(y, \\widehat y) = \\frac{1}{\\sum w_i} \\sum_i w_i 1\\{\\widehat y_i = y_i\\}\n",
    "$$\n",
    "with $w_i = \\frac{1}{\\sum_j 1\\{y_j = y_i\\}}$, the frequency of class $y_i$ in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of the default model is 0.500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "print(f\"The balanced accuracy of the default model is \"\n",
    "      f\"{balanced_accuracy_score(target, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can have a look at the confusion matrix to a real idea of what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37155,     0],\n",
       "       [11687,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(\n",
    "    confusion_matrix(target, y_pred),\n",
    "    columns=dummy_clf.classes_,\n",
    "    index=dummy_clf.classes_\n",
    ")\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 16},\n",
    "            cmap='Oranges',)\n",
    "\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the first part of the lab, the confusion matrix can be summarized using several metrics\n",
    "\n",
    "* precision and recall\n",
    "* sensitivity and specificity\n",
    "* area under the roc curve (ROC-AUC)\n",
    "\n",
    "NB: sensitivity = recall\n",
    " \n",
    "If we take as a positive class `' >50K'`, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the dummy model is 0.0\n",
      "The precision of the dummy model is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/.local/miniconda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "precision = precision_score(\n",
    "    target, y_pred, pos_label=' >50K')\n",
    "recall = recall_score(\n",
    "    target, y_pred, pos_label=' >50K')\n",
    "\n",
    "print(f\"The recall of the dummy model is \"\n",
    "      f\"{recall}\")\n",
    "print(f\"The precision of the dummy model is \"\n",
    "      f\"{precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity of the dummy model is 0.0\n",
      "The specificity of the dummy model is 1.0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import sensitivity_score\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "sensitivity = sensitivity_score(\n",
    "    target, y_pred, pos_label=' >50K')\n",
    "specificity = specificity_score(\n",
    "   target, y_pred, pos_label=' >50K')\n",
    "\n",
    "print(f\"The sensitivity of the dummy model is \"\n",
    "      f\"{sensitivity}\")\n",
    "print(f\"The specificity of the dummy model is \"\n",
    "      f\"{specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: How to solve the issue during `fit`\n",
    "\n",
    "In this part, we will see how we can adapt the model to cope with imbalanced dataset.\n",
    "First, we split the data in a train and a test set. Then we review various way to handle imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the different models\n",
    "def evaluate_classifier(clf):\n",
    "    name = getattr(clf, 'name', clf.__class__.__name__)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    balanced_score = balanced_accuracy_score(y_test, y_pred)\n",
    "    display(HTML(\n",
    "        f\"<h5>{name}</h5>\"\n",
    "        f\"Test Accuracy: {score:7.2%} <br/>\"\n",
    "        f\"Balanced accuracy: {balanced_score:7.2%} <br/>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline classifier\n",
    "\n",
    "As we have seen before, we will compare the new classifiers with a dummy baseline which predict the most frequent label in the dataset. This baseline will highlight the improvement compared to naive strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Most Frequent Classifier</h5>Test Accuracy:  75.94% <br/>Balanced accuracy:  50.00% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.name = \"Most Frequent Classifier\"\n",
    "\n",
    "evaluate_classifier(dummy_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Make use of the `class_weight` parameter\n",
    "\n",
    "A first class of methods rely on sample weights to correct the imbalance. The core idea here is to weight prediction mistakes on the minority class higher than mistakes on the most common class.\n",
    "\n",
    "#### In linear model\n",
    "\n",
    "In `scikit-learn`, some estimators have a `class_weight` parameter that permits to do this. The idea is that the ERM is changed such that\n",
    "$$\n",
    "    \\arg\\min_\\theta \\frac{1}{\\sum_i w_i} \\sum_i w_i 1\\{f_\\theta(X_i) = y_i\\}\n",
    "$$\n",
    "with weights $w_i = \\frac{n}{kn_i}$ with $n$ the total number of samples, $k$ the number of classes and $n_i$ the number of samples from class $y_i$. This effectively rebalance the training in learning both from positive and negative examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoding_columns = ['sex']\n",
    "one_hot_encoding_columns = ['workclass', 'education', 'marital-status',\n",
    "                            'occupation', 'relationship',\n",
    "                            'race', 'native-country']\n",
    "scaling_columns = ['age', 'education-num', 'hours-per-week',\n",
    "                   'capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "preprocessor_lr = ColumnTransformer([\n",
    "    ('binary-encoder', OrdinalEncoder(), binary_encoding_columns),\n",
    "    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'),\n",
    "     one_hot_encoding_columns),\n",
    "    ('standard-scaler', StandardScaler(), scaling_columns)\n",
    "])\n",
    "model_lr = make_pipeline(\n",
    "    preprocessor_lr,\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "model_lr.name = \"Logistic Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Logistic Regression</h5>Test Accuracy:  85.23% <br/>Balanced accuracy:  76.65% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the `class_weight='balanced'` uses the values of `y` to automatically adjust weights inversely proportional to class frequencies in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Logistic Regression with balanced weights</h5>Test Accuracy:  80.74% <br/>Balanced accuracy:  81.68% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lr_balanced = clone(model_lr)\n",
    "model_lr_balanced.set_params(\n",
    "    logisticregression__class_weight='balanced')\n",
    "model_lr_balanced.name = \"Logistic Regression with balanced weights\"\n",
    "evaluate_classifier(model_lr_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In tree-based model\n",
    "\n",
    "In tree based models, the `class_weight` option is used to chose on the splits. Indeed, the purity criterion (which is minimize for to chose the split) is computed using these weights. In the leaf, the weights are used to compute the class to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoding_columns = ['workclass', 'education', 'marital-status',\n",
    "                            'occupation', 'relationship', 'sex',\n",
    "                            'race', 'native-country']\n",
    "scaling_columns = ['age', 'education-num', 'hours-per-week',\n",
    "                   'capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "preprocessor_rf = ColumnTransformer([\n",
    "    ('binary-encoder', OrdinalEncoder(), ordinal_encoding_columns),\n",
    "    ('standard-scaler', FunctionTransformer(validate=False), scaling_columns)\n",
    "])\n",
    "model_rf = make_pipeline(\n",
    "    preprocessor_rf,\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "model_rf.name = \"Random Forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Random Forest</h5>Test Accuracy:  84.83% <br/>Balanced accuracy:  77.03% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Balanced Random Forest</h5>Test Accuracy:  84.43% <br/>Balanced accuracy:  77.40% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rf_balanced = clone(model_rf)\n",
    "model_rf_balanced.set_params(\n",
    "    randomforestclassifier__class_weight='balanced')\n",
    "model_rf_balanced.name = \"Balanced Random Forest\"\n",
    "\n",
    "evaluate_classifier(model_rf_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ensemble models, `class_weight` can also take value `balanced_subsample`. This option is equivalent to the `'balanced'` one except that the weigths are computed directly for the bootstrap sample of each tree instead of weights computed globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Balanced Subsample Random Forest</h5>Test Accuracy:  84.49% <br/>Balanced accuracy:  77.59% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rf_subbalanced = clone(model_rf)\n",
    "model_rf_subbalanced.set_params(\n",
    "    randomforestclassifier__class_weight='balanced_subsample')\n",
    "model_rf_subbalanced.name = \"Balanced Subsample Random Forest\"\n",
    "\n",
    "evaluate_classifier(model_rf_subbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Resample the training set to have balanced classes\n",
    "\n",
    "A second option to learn on unbalanced data is to reweight the classes by sampling a new training set with balanced class. This can be done by either subsampling, oversampling or more complicated scheme demonstrated in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random under-sampling during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_undersampled = make_pipeline_imblearn(\n",
    "    preprocessor_lr,\n",
    "    RandomUnderSampler(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "model_lr_undersampled.name = \"Logistic Regression from rebalanced undersampled data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Logistic Regression from rebalanced undersampled data</h5>Test Accuracy:  80.73% <br/>Balanced accuracy:  81.72% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_lr_undersampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random over-sampling during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_oversampled = make_pipeline_imblearn(\n",
    "    preprocessor_lr,\n",
    "    RandomOverSampler(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "model_lr_oversampled.name = \"Logistic Regression from rebalanced oversampled data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Logistic Regression from rebalanced oversampled data</h5>Test Accuracy:  80.74% <br/>Balanced accuracy:  81.62% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_lr_oversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More fancy methods\n",
    "\n",
    "\n",
    "There exists some more fancy methods to re-balance the dataset. For instance the SMOTE method where extra points are generated by creatinig synthetic points for the minority class. See more info on the [original paper](https://arxiv.org/pdf/1106.1813.pdf) or in this [blog post](http://rikunert.com/SMOTE_explained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_smote = make_pipeline_imblearn(\n",
    "    preprocessor_lr,\n",
    "    SMOTE(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "model_lr_smote.name = \"Logistic Regression from SMOTE sampled data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Logistic Regression from SMOTE sampled data</h5>Test Accuracy:  80.79% <br/>Balanced accuracy:  81.63% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_lr_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look in [imbalanced-learn documentation](https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.over_sampling) for more sampling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Used balanced algorithms: `BalancedRandomForest` and `BalancedBaggingClassifier` \n",
    "\n",
    "Instead of just sampling the training set to rebalance the classes, it is also possible to used _balanced_ classifier to fit the unbalanced dataset. The core idea is to use ensemble techniques with specific boostrap sampling strategies that make sure that each bootstrap sample is balanced.\n",
    "\n",
    "#### Example of `BalancedRandomForestClassifier`\n",
    "\n",
    "Here, a random forest is learn on the full dataset. Each tree is constructed using a balanced sub-sampled of the dataset.  \n",
    "This idea has been proposed by [Chen et al. (2004)](https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "model_balanced_rf = make_pipeline(\n",
    "    preprocessor_rf,\n",
    "    BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "model_balanced_rf.name = \"Balanced Random Forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Balanced Random Forest</h5>Test Accuracy:  81.45% <br/>Balanced accuracy:  83.04% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_balanced_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of `BalancedBaggingClassifier`\n",
    "\n",
    "In ensemble classifiers, bagging methods build several estimators on different randomly selected subset of data. In scikit-learn, this classifier is named `BaggingClassifier`. However, this classifier does not allow to balance each subset of data. Therefore, when training on imbalanced data set, this classifier will favor the majority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagging = make_pipeline(\n",
    "    preprocessor_rf,\n",
    "    BaggingClassifier(base_estimator=HistGradientBoostingClassifier(),\n",
    "                      n_estimators=10, random_state=42)\n",
    ")\n",
    "model_bagging.name = \"Bagging Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(model_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BalancedBaggingClassifier `allows to resample each subset of data before to train each estimator of the ensemble. In short, it combines the output of an `EasyEnsemble` sampler with an ensemble of classifiers (i.e. `BaggingClassifier`). Therefore, `BalancedBaggingClassifier `takes the same parameters than the scikit-learn `BaggingClassifier`. Additionally, there is two additional parameters, sampling_strategy and replacement to control the behaviour of the random under-sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "model_balanced_bagging = make_pipeline(\n",
    "    preprocessor_rf,\n",
    "    BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(),\n",
    "                              n_estimators=10, random_state=42)\n",
    ")\n",
    "model_balanced_bagging.name = \"Balanced Bagging Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Balanced Bagging Model</h4><br/>Test Accuracy:  83.26% <br/>Balanced accuracy:  84.55% <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_classifier(model_balanced_bagging)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
